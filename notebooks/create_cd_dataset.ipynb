{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import jsonlines\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:46<00:00,  1.84it/s]\n",
      "  0%|          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 4237 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:44<00:00,  1.89it/s]\n",
      "  0%|          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 10582 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:47<00:00,  1.83it/s]\n",
      "  0%|          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 2984 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:46<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 5579 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:45<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 4472 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "schema_descr_path = '../data/schemas/descrs'\n",
    "cgw_schema_rel_docs_path = '../data/cgw/schema_related/pos'\n",
    "cgw_preds_args_path = '../data/cgw/preds_args'\n",
    "\n",
    "data_split = {y: 'train' for y in range(1994, 2007)}\n",
    "data_split.update({2007: 'dev', 2008: 'dev', 2009: 'test', 2010: 'test'})\n",
    "\n",
    "for filename in os.listdir(schema_descr_path):\n",
    "    if not filename.endswith('.json'):\n",
    "        continue\n",
    "    schema_name = filename[:-5]\n",
    "\n",
    "    subset_docs_ids = set()\n",
    "\n",
    "    # Collect schema-related docs' ids\n",
    "    with jsonlines.open(f'{cgw_schema_rel_docs_path}/{schema_name}.jsonl') as reader:\n",
    "        for doc in reader:\n",
    "            subset_docs_ids.add(doc['id'])\n",
    "    \n",
    "    # Load schema events\n",
    "    with open(f'{schema_descr_path}/{schema_name}.json') as fin:\n",
    "        schema_descr = json.load(fin)\n",
    "        filtered_events = schema_descr['predpatt']\n",
    "    \n",
    "    # Load all docs\n",
    "    subset_raw_docs_ids = []\n",
    "    subset_raw_docs = []\n",
    "\n",
    "    for pred_arg_path in tqdm(glob(f'{cgw_preds_args_path}/*.jsonl')):\n",
    "        with jsonlines.open(pred_arg_path) as reader:\n",
    "            for doc in reader:\n",
    "                assert doc['filename'].endswith('.comm')\n",
    "                doc_id = doc['filename'][:-5]\n",
    "                doc_split = data_split[int(doc_id[8:12])]\n",
    "                if doc_split != 'train':\n",
    "                    continue\n",
    "                # if doc_id in subset_docs_ids:  # read only a subset of documents\n",
    "                # pred_only_doc = [f'{a0 if ix == 0 else a1}_{ix}' for a0, a1, ix in doc['preds_args']]\n",
    "                doc_repr = [(a0 if ix == 0 else a1) for a0, a1, ix in doc['preds_args']]\n",
    "                doc_repr = [e for e in doc_repr if e in filtered_events]\n",
    "                if len(doc_repr) > 5:\n",
    "                    subset_raw_docs_ids.append(doc_id)\n",
    "                    subset_raw_docs.append(doc_repr)\n",
    "    \n",
    "    subset_raw_docs_ids = np.array(subset_raw_docs_ids)\n",
    "    assert len(subset_raw_docs) == len(subset_raw_docs_ids)\n",
    "\n",
    "    # Vectorize docs\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "    subset_tfidf = vectorizer.fit_transform(subset_raw_docs)\n",
    "    subset_tfidf = subset_tfidf.toarray()\n",
    "    \n",
    "    # Output to CSV\n",
    "    header = [v for k, v in sorted([(v, k) for k, v in vectorizer.vocabulary_.items()])]\n",
    "    vocab_size = len(vectorizer.vocabulary_)\n",
    "\n",
    "    with open(f'{cgw_schema_rel_docs_path}/{schema_name}_binary_{vocab_size}.csv', 'w') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow(header)\n",
    "        for row in np.int32(subset_tfidf > 0):\n",
    "            writer.writerow(list(row))\n",
    "    print(f'Output {len(subset_tfidf)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with argument generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets = {\n",
    "    \"ce_001_protest\": {\n",
    "        \"police\": wn.synset('law_enforcement_agency.n.01').name(),\n",
    "        \"bush\": wn.synset('politician.n.02').name(),\n",
    "        \"putin\": wn.synset('politician.n.02').name(),\n",
    "        \"hussein\": wn.synset('politician.n.02').name(),\n",
    "        \"hizballah\": wn.synset('politician.n.02').name(),\n",
    "        \"hezbollah\": wn.synset('politician.n.02').name(),\n",
    "        \"gore\": wn.synset('politician.n.02').name(),\n",
    "        \"politician\": wn.synset('politician.n.02').name(),\n",
    "        \"gore\": wn.synset('politician.n.02').name(),\n",
    "        \n",
    "        \"city\": wn.synset('urban_area.n.01').name(),\n",
    "        \"broadway\": wn.synset('urban_area.n.01').name(),\n",
    "        \"orleans\": wn.synset('urban_area.n.01').name(),\n",
    "        \"tokyo\": wn.synset('urban_area.n.01').name(),\n",
    "        \"selma\": wn.synset('urban_area.n.01').name(),\n",
    "        \"guadalajara\": wn.synset('urban_area.n.01').name(),\n",
    "        \"paris\": wn.synset('urban_area.n.01').name(),\n",
    "        \"zaragoza\": wn.synset('urban_area.n.01').name(),\n",
    "        \"beijing\": wn.synset('urban_area.n.01').name(),\n",
    "        \"washington\": wn.synset('urban_area.n.01').name(),\n",
    "        \"zaragoza\": wn.synset('urban_area.n.01').name(),\n",
    "        \n",
    "        \"demonstrator\": wn.synset('reformer.n.01').name(),\n",
    "        \"protester\": wn.synset('reformer.n.01').name(),\n",
    "        \"demonstration\": wn.synset('protest.n.02').name(),\n",
    "        \"protest\": wn.synset('protest.n.02').name(),\n",
    "        \"sit-in\": wn.synset('protest.n.02').name(),\n",
    "        \"march\": wn.synset('protest.n.02').name(),\n",
    "        \"rally\": wn.synset('protest.n.02').name(),\n",
    "        \n",
    "        \"woman\": wn.synset('person.n.01').name(),\n",
    "        \"man\": wn.synset('person.n.01').name(),\n",
    "        \"daughter\": wn.synset('person.n.01').name(),\n",
    "        \"student\": wn.synset('person.n.01').name(),\n",
    "        \"group\": wn.synset('group.n.01').name(),\n",
    "\n",
    "        \"japan\": wn.synset('political_unit.n.01').name(),\n",
    "        \"china\": wn.synset('political_unit.n.01').name(),\n",
    "        \"israel\": wn.synset('political_unit.n.01').name(),\n",
    "        \"isreal\": wn.synset('political_unit.n.01').name(),\n",
    "        \"egypt\": wn.synset('political_unit.n.01').name(),\n",
    "        \"lithuania\": wn.synset('political_unit.n.01').name(),\n",
    "        \"lebanon\": wn.synset('political_unit.n.01').name(),\n",
    "        \"haiti\": wn.synset('political_unit.n.01').name(),\n",
    "        \"fiji\": wn.synset('political_unit.n.01').name(),\n",
    "        \"nigeria\": wn.synset('political_unit.n.01').name(),\n",
    "        \"cuba\": wn.synset('political_unit.n.01').name(),\n",
    "        \"iraq\": wn.synset('political_unit.n.01').name(),\n",
    "        \"uganda\": wn.synset('political_unit.n.01').name(),\n",
    "        \"cuba\": wn.synset('political_unit.n.01').name(),\n",
    "        \"cuba\": wn.synset('political_unit.n.01').name(),\n",
    "        \"cuba\": wn.synset('political_unit.n.01').name(),\n",
    "        \"cuba\": wn.synset('political_unit.n.01').name(),\n",
    "    },\n",
    "    \"ce_005_disease_outbreak\": {\n",
    "        \"organism\": wn.synset('organism.n.01').name(),\n",
    "        \"fly\": wn.synset('organism.n.01').name(),\n",
    "        \"cat\": wn.synset('organism.n.01').name(),\n",
    "        \"rat\": wn.synset('organism.n.01').name(),\n",
    "        \"mosquito\": wn.synset('organism.n.01').name(),\n",
    "        \"cattle\": wn.synset('organism.n.01').name(),\n",
    "        \"bird\": wn.synset('organism.n.01').name(),\n",
    "        \"mouse\": wn.synset('organism.n.01').name(),\n",
    "        \"gorilla\": wn.synset('organism.n.01').name(),\n",
    "        \"deer\": wn.synset('organism.n.01').name(),\n",
    "        \"horse\": wn.synset('organism.n.01').name(),\n",
    "        \"worm\": wn.synset('organism.n.01').name(),\n",
    "        \"bat\": wn.synset('organism.n.01').name(),\n",
    "        \"sheep\": wn.synset('organism.n.01').name(),\n",
    "        \"cow\": wn.synset('organism.n.01').name(),\n",
    "        \"dog\": wn.synset('organism.n.01').name(),\n",
    "        \"livestock\": wn.synset('organism.n.01').name(),\n",
    "        \"bison\": wn.synset('organism.n.01').name(),\n",
    "        \"duck\": wn.synset('organism.n.01').name(),\n",
    "        \"frog\": wn.synset('organism.n.01').name(),\n",
    "        \"chimpanzee\": wn.synset('organism.n.01').name(),\n",
    "        \"pigeon\": wn.synset('organism.n.01').name(),\n",
    "        \"swan\": wn.synset('organism.n.01').name(),\n",
    "        \"shellfish\": wn.synset('organism.n.01').name(),\n",
    "        \"pig\": wn.synset('organism.n.01').name(),\n",
    "        \"salmon\": wn.synset('organism.n.01').name(),\n",
    "        \"trout\": wn.synset('organism.n.01').name(),\n",
    "        \"tick\": wn.synset('organism.n.01').name(),\n",
    "        \"fish\": wn.synset('organism.n.01').name(),\n",
    "        \"ferret\": wn.synset('organism.n.01').name(),\n",
    "        \"rodent\": wn.synset('organism.n.01').name(),\n",
    "        \"gerbil\": wn.synset('organism.n.01').name(),\n",
    "        \"hamster\": wn.synset('organism.n.01').name(),\n",
    "        \"raccoon\": wn.synset('organism.n.01').name(),\n",
    "        \"lion\": wn.synset('organism.n.01').name(),\n",
    "        \"crab\": wn.synset('organism.n.01').name(),\n",
    "        \"elk\": wn.synset('organism.n.01').name(),\n",
    "        \"mammal\": wn.synset('organism.n.01').name(),\n",
    "        \"toad\": wn.synset('organism.n.01').name(),\n",
    "        \"salmon\": wn.synset('organism.n.01').name(),\n",
    "        \n",
    "        \"poultry\": wn.synset('food.n.02').name(),\n",
    "        \"beef\": wn.synset('food.n.02').name(),\n",
    "                \n",
    "        \"mumps\": wn.synset('illness.n.01').name(),\n",
    "        \"meningitis\": wn.synset('illness.n.01').name(),\n",
    "        \"polio\": wn.synset('illness.n.01').name(),\n",
    "        \"tuberculosis\": wn.synset('illness.n.01').name(),\n",
    "        \"dysentery\": wn.synset('illness.n.01').name(),\n",
    "        \"leprosy\": wn.synset('illness.n.01').name(),\n",
    "        \"cholera\": wn.synset('illness.n.01').name(),\n",
    "        \"herpes\": wn.synset('illness.n.01').name(),\n",
    "        \"fibrosis\": wn.synset('illness.n.01').name(),\n",
    "        \"osteoporosis\": wn.synset('illness.n.01').name(),\n",
    "        \"sclerosis\": wn.synset('illness.n.01').name(),\n",
    "        \"influenza\": wn.synset('illness.n.01').name(),\n",
    "        \"flu\": wn.synset('illness.n.01').name(),\n",
    "        \"sickness\": wn.synset('illness.n.01').name(),\n",
    "        \"infection\": wn.synset('illness.n.01').name(),\n",
    "        \"illness\": wn.synset('illness.n.01').name(),\n",
    "        \"injury\": wn.synset('illness.n.01').name(),\n",
    "        \"leukemia\": wn.synset('illness.n.01').name(),\n",
    "        \"carcinoma\": wn.synset('illness.n.01').name(),\n",
    "        \"hiv\": wn.synset('illness.n.01').name(),\n",
    "        \"asbestosis\": wn.synset('illness.n.01').name(),\n",
    "        \"smallpox\": wn.synset('illness.n.01').name(),\n",
    "        \"rabies\": wn.synset('illness.n.01').name(),\n",
    "        \"anemia\": wn.synset('illness.n.01').name(),\n",
    "        \"encephalitis\": wn.synset('illness.n.01').name(),\n",
    "        \"zoonosis\": wn.synset('illness.n.01').name(),\n",
    "        \"rinderpest\": wn.synset('illness.n.01').name(),\n",
    "        \"bse\": wn.synset('illness.n.01').name(),\n",
    "        \"osteoarthritis\": wn.synset('illness.n.01').name(),\n",
    "        \"sepsis\": wn.synset('illness.n.01').name(),\n",
    "        \"cancer\": wn.synset('illness.n.01').name(),\n",
    "        \"trachoma\": wn.synset('illness.n.01').name(),\n",
    "        \"malaria\": wn.synset('illness.n.01').name(),\n",
    "        \"melanoma\": wn.synset('illness.n.01').name(),\n",
    "        \"angioma\": wn.synset('illness.n.01').name(),\n",
    "        \"plague\": wn.synset('illness.n.01').name(),\n",
    "        \"sars\": wn.synset('illness.n.01').name(),\n",
    "        \"pneumonia\": wn.synset('illness.n.01').name(),\n",
    "        \"parkinson\": wn.synset('illness.n.01').name(),\n",
    "        \"psoriasis\": wn.synset('illness.n.01').name(),\n",
    "        \"arthritis\": wn.synset('illness.n.01').name(),\n",
    "        \"mucopolysaccharidosis\": wn.synset('illness.n.01').name(),\n",
    "        \"gonorrhea\": wn.synset('illness.n.01').name(),\n",
    "        \"plague\": wn.synset('illness.n.01').name(),\n",
    "        \"plague\": wn.synset('illness.n.01').name(),\n",
    "        \"plague\": wn.synset('illness.n.01').name(),\n",
    "        \"plague\": wn.synset('illness.n.01').name(),\n",
    "   \n",
    "        \"intestine\": wn.synset('body_part.n.01').name(),\n",
    "        \"liver\": wn.synset('body_part.n.01').name(),\n",
    "        \"lung\": wn.synset('body_part.n.01').name(),\n",
    "        \"heart\": wn.synset('body_part.n.01').name(),\n",
    "        \"lung\": wn.synset('body_part.n.01').name(),\n",
    "        \"lung\": wn.synset('body_part.n.01').name(),\n",
    "        \"lung\": wn.synset('body_part.n.01').name(),\n",
    "        \"lung\": wn.synset('body_part.n.01').name(),\n",
    "\n",
    "        \"bacillus\": wn.synset('infectious_agent.n.01').name(),\n",
    "        \"spirochete\": wn.synset('infectious_agent.n.01').name(),\n",
    "        \"microbe\": wn.synset('infectious_agent.n.01').name(),\n",
    "        \"bacteria\": wn.synset('infectious_agent.n.01').name(),\n",
    "        \"bacterium\": wn.synset('infectious_agent.n.01').name(),\n",
    "        \"bacillus\": wn.synset('infectious_agent.n.01').name(),\n",
    "                \n",
    "    },\n",
    "    \"election\": {\n",
    "        \"candidate\": wn.synset('campaigner.n.01').name(),\n",
    "        \"nominee\": wn.synset('campaigner.n.01').name(),\n",
    "        \"candidate\": wn.synset('campaigner.n.01').name(),\n",
    "        \"pac\": wn.synset('campaigner.n.01').name(),\n",
    "        \n",
    "        \"amendment\": wn.synset('legislation.n.01').name(),\n",
    "        \"bill\": wn.synset('legislation.n.01').name(),\n",
    "        \"treaty\": wn.synset('legislation.n.01').name(),\n",
    "        \"contract\": wn.synset('legislation.n.01').name(),\n",
    "        \"document.n.01\": wn.synset('legislation.n.01').name(),\n",
    "        \n",
    "        \"kennedy\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"administrative_unit.n.01\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"presiding_officer.n.01\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"clergyman.n.01\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"chief\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"chieftain\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"lawmaker\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"politician\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"bush\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"gore\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"clinton\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"nixon\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"president\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"governor\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"whip\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"senator\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"congresswoman\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"congressman\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"sheriff\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"deputy\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"representative\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"king\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"emperor\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"czar\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"judge\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"congress\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"parliament\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"senate\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"duma\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"eisenhower\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"house\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"jefferson\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"cabinet\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"official\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"representative.n.01\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"speaker\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"general\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"polity.n.02\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"legislator\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"hussein\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"mandela\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"reagan\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"buchanan\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"hussein\": wn.synset('civil_authority.n.01').name(),\n",
    "        \"lawman.n.01\": wn.synset('civil_authority.n.01').name(),\n",
    "        \n",
    "        \"conservative\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"liberal\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"moderate\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"nationalist\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"center\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"middle\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"left\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"right\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"separatist\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"libertarian\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"democrat\": wn.synset('political_orientation.n.01').name(),  # or party.n.01?\n",
    "        \"republican\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"communist\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"socialist\": wn.synset('political_orientation.n.01').name(),\n",
    "        \"independent\": wn.synset('political_orientation.n.01').name(),\n",
    "\n",
    "        \"people\": wn.synset('people.n.01').name(),\n",
    "        \"adult.n.01\": wn.synset('people.n.01').name(),\n",
    "        \"person.n.01\": wn.synset('people.n.01').name(),\n",
    "        \n",
    "        \"decision\": wn.synset('vote.n.01').name(),\n",
    "        \"vote\": wn.synset('vote.n.01').name(),\n",
    "        \"voting\": wn.synset('vote.n.01').name(),\n",
    "        \n",
    "        \"voter\": wn.synset('voter.n.01').name(),\n",
    "        \"elector\": wn.synset('voter.n.01').name(),\n",
    "        \n",
    "        \"negative.n.01\": wn.synset('result.n.03').name(),\n",
    "        \"affirmative.n.01\": wn.synset('result.n.03').name(),\n",
    "        \"ending.n.04\": wn.synset('result.n.03').name(),\n",
    "        \n",
    "        \"colombia\": wn.synset('political_unit.n.01').name(),\n",
    "        \"mexico\": wn.synset('political_unit.n.01').name(),\n",
    "        \"georgia\": wn.synset('political_unit.n.01').name(),\n",
    "        \"florida\": wn.synset('political_unit.n.01').name(),\n",
    "        \"carolina\": wn.synset('political_unit.n.01').name(),\n",
    "        \"colorado\": wn.synset('political_unit.n.01').name(),\n",
    "        \"washington\": wn.synset('political_unit.n.01').name(),\n",
    "        \"texas\": wn.synset('political_unit.n.01').name(),\n",
    "        \"new_jersey.n.01\": wn.synset('political_unit.n.01').name(),\n",
    "        \"missouri\": wn.synset('political_unit.n.01').name(),\n",
    "        \"mississippi\": wn.synset('political_unit.n.01').name(),\n",
    "        \"united_kingdom.n.01\": wn.synset('political_unit.n.01').name(),\n",
    "        \"israel.n.01\": wn.synset('political_unit.n.01').name(),\n",
    "        \"california\": wn.synset('political_unit.n.01').name(),\n",
    "        \"peru\": wn.synset('political_unit.n.01').name(),\n",
    "        \"province\": wn.synset('political_unit.n.01').name(),\n",
    "        \"state\": wn.synset('political_unit.n.01').name(),\n",
    "        \"country\": wn.synset('political_unit.n.01').name(),\n",
    "        \"district\": wn.synset('political_unit.n.01').name(),\n",
    "        \"municipality.n.01\": wn.synset('political_unit.n.01').name(),\n",
    "        \"america\": wn.synset('political_unit.n.01').name(),\n",
    "        \"ireland.n.01\": wn.synset('political_unit.n.01').name(),\n",
    "        \n",
    "        \"white\": wn.synset('demographic.n.01').name(),\n",
    "        \"black\": wn.synset('demographic.n.01').name(),\n",
    "        \"women\": wn.synset('demographic.n.01').name(),\n",
    "        \"men\": wn.synset('demographic.n.01').name(),\n",
    "        \"worker\": wn.synset('demographic.n.01').name(),\n",
    "        \"gay\": wn.synset('demographic.n.01').name(),\n",
    "        \"homosexual\": wn.synset('demographic.n.01').name(),\n",
    "        \"jew\": wn.synset('demographic.n.01').name(),\n",
    "        \"age\": wn.synset('demographic.n.01').name(),\n",
    "        \"old\": wn.synset('demographic.n.01').name(),\n",
    "        \"young\": wn.synset('demographic.n.01').name(),\n",
    "        \"muslim.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"social_group.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"arab.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"south_american.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"american.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"asian.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"latino\": wn.synset('demographic.n.01').name(),\n",
    "        \"inhabitant.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"absentee\": wn.synset('demographic.n.01').name(),\n",
    "        \"central_american.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"catholic.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"christian.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"religious_person.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \"juvenile.n.01\": wn.synset('demographic.n.01').name(),\n",
    "        \n",
    "        \"large_integer.n.01\": wn.synset(\"number.n.01\").name(),\n",
    "        \"proportion.n.01\": wn.synset(\"number.n.01\").name(),\n",
    "        \"common_fraction.n.01\": wn.synset(\"number.n.01\").name(),\n",
    "        \"digit.n.01\": wn.synset(\"number.n.01\").name(),\n",
    "        \"large_indefinite_quantity.n.01\": wn.synset(\"number.n.01\").name(),\n",
    "    },\n",
    "    \"ce_040_arrest\": {\n",
    "        \"murder\": wn.synset('crime.n.01').name(),\n",
    "        \"smuggling\": wn.synset('crime.n.01').name(),\n",
    "        \"intimidation\": wn.synset('crime.n.01').name(),\n",
    "        \"assault\": wn.synset('crime.n.01').name(),\n",
    "        \"scam\": wn.synset('crime.n.01').name(),\n",
    "        \"kidnapping\": wn.synset('crime.n.01').name(),\n",
    "        \"killing\": wn.synset('crime.n.01').name(),\n",
    "        \n",
    "        \"trafficker\": wn.synset('criminal.n.01').name(),\n",
    "        \"dealer\": wn.synset('criminal.n.01').name(),\n",
    "        \"shoplifter\": wn.synset('criminal.n.01').name(),\n",
    "        \"rioter\": wn.synset('criminal.n.01').name(),\n",
    "        \"troublemaker\": wn.synset('criminal.n.01').name(),\n",
    "        \"plotter\": wn.synset('criminal.n.01').name(),\n",
    "        \"abductor\": wn.synset('criminal.n.01').name(),\n",
    "        \"offender\": wn.synset('criminal.n.01').name(),\n",
    "        \"hijacker\": wn.synset('criminal.n.01').name(),\n",
    "        \"rapist\": wn.synset('criminal.n.01').name(),\n",
    "        \"stoner\": wn.synset('criminal.n.01').name(),\n",
    "        \"predator\": wn.synset('criminal.n.01').name(),\n",
    "        \"felon\": wn.synset('criminal.n.01').name(),\n",
    "        \"criminal\": wn.synset('criminal.n.01').name(),\n",
    "        \"pimp\": wn.synset('criminal.n.01').name(),\n",
    "        \"abuser\": wn.synset('criminal.n.01').name(),\n",
    "        \"attacker\": wn.synset('criminal.n.01').name(),\n",
    "        \"perpetrator\": wn.synset('criminal.n.01').name(),\n",
    "        \"pedophile\": wn.synset('criminal.n.01').name(),\n",
    "        \"flasher\": wn.synset('criminal.n.01').name(),\n",
    "        \n",
    "        # Group special witnesses together (doctor, psychologist, etc)\n",
    "\n",
    "        \"police\": wn.synset('law_enforcement_agency.n.01').name(),\n",
    "        \"bush\": wn.synset('politician.n.02').name(),\n",
    "\n",
    "        \"syria\": wn.synset('political_unit.n.01').name(),\n",
    "        \"iraq\": wn.synset('political_unit.n.01').name(),\n",
    "        \"yugoslavia\": wn.synset('political_unit.n.01').name(),\n",
    "        \"zagreb\": wn.synset('political_unit.n.01').name(),\n",
    "        \"nato\": wn.synset('political_unit.n.01').name(),\n",
    "        \"europe\": wn.synset('political_unit.n.01').name(),\n",
    "        \"eritrea\": wn.synset('political_unit.n.01').name(),\n",
    "        \"lebanon\": wn.synset('political_unit.n.01').name(),\n",
    "        \"haiti\": wn.synset('political_unit.n.01').name(),\n",
    "        \"fiji\": wn.synset('political_unit.n.01').name(),\n",
    "        \"nigeria\": wn.synset('political_unit.n.01').name(),\n",
    "        \"cuba\": wn.synset('political_unit.n.01').name(),\n",
    "        \"uganda\": wn.synset('political_unit.n.01').name(),\n",
    "        \"pakistan\": wn.synset('political_unit.n.01').name(),\n",
    "        \"iran\": wn.synset('political_unit.n.01').name(),\n",
    "        \"belgium\": wn.synset('political_unit.n.01').name(),\n",
    "        \"spain\": wn.synset('political_unit.n.01').name(),\n",
    "        \"bengal\": wn.synset('political_unit.n.01').name(),\n",
    "        \n",
    "        \"diplomat\": wn.synset('politician.n.02').name(),\n",
    "        \"vargas\": wn.synset('politician.n.02').name(),\n",
    "        \"putin\": wn.synset('politician.n.02').name(),\n",
    "        \"chiluba\": wn.synset('politician.n.02').name(),\n",
    "        \"president\": wn.synset('politician.n.02').name(),\n",
    "    },\n",
    "    \"plane_crash\": {\n",
    "        \"plane\": wn.synset('airplane.n.01').name(),\n",
    "        \"helicopter\": wn.synset('airplane.n.01').name(),\n",
    "        \"sailplane\": wn.synset('airplane.n.01').name(),\n",
    "        \"airplane\": wn.synset('airplane.n.01').name(),\n",
    "        \"glider\": wn.synset('airplane.n.01').name(),\n",
    "        \"warplane\": wn.synset('airplane.n.01').name(),\n",
    "        \"jetliner\": wn.synset('airplane.n.01').name(),\n",
    "        \"aircraft\": wn.synset('airplane.n.01').name(),\n",
    "        \"turboprop\": wn.synset('airplane.n.01').name(),\n",
    "        \"warplane\": wn.synset('airplane.n.01').name(),\n",
    "        \"warplane\": wn.synset('airplane.n.01').name(),\n",
    "        \"warplane\": wn.synset('airplane.n.01').name(),\n",
    "    }\n",
    "}\n",
    "\n",
    "stopwords = {\"we\", \"they\", \"who\", \"which\", \"that\", \"i\", \"it\", \"he\", \"she\", \"them\", \"him\", \"her\", \"u\", \"me\", \"a\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_descr_path = '../data/schemas/descrs'\n",
    "cgw_schema_rel_docs_path = '../data/cgw/schema_related/pos'\n",
    "cgw_preds_args_path = '../data/cgw/preds_args'\n",
    "\n",
    "data_split = {y: 'train' for y in range(1994, 2007)}\n",
    "data_split.update({2007: 'dev', 2008: 'dev', 2009: 'test', 2010: 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = 'election'\n",
    "\n",
    "# Load schema events\n",
    "with open(f'{schema_descr_path}/{schema_name}.json') as fin:\n",
    "    schema_descr = json.load(fin)\n",
    "    filtered_events = {tuple(x) for x in schema_descr['predpatt_wordnet']}\n",
    "    filtered_events_preds = {pred for pred, *_ in filtered_events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [02:06<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all docs\n",
    "subset_raw_docs_ids = []\n",
    "subset_raw_docs = []\n",
    "subset_event_cntr = collections.Counter()\n",
    "\n",
    "for pred_arg_path in tqdm(glob(f'{cgw_preds_args_path}/*.jsonl')):\n",
    "    with jsonlines.open(pred_arg_path) as reader:\n",
    "        for doc in reader:\n",
    "            assert doc['filename'].endswith('.comm')\n",
    "            doc_id = doc['filename'][:-5]\n",
    "            doc_split = data_split[int(doc_id[8:12])]\n",
    "            if doc_split != 'train':\n",
    "                continue\n",
    "            # if doc_id in subset_docs_ids:\n",
    "            doc_repr = []\n",
    "            for pred_args in doc['preds_args']:\n",
    "                pred_idx = pred_args[2]\n",
    "                arg_idx = 1 - pred_idx\n",
    "                pred, arg = pred_args[pred_idx], pred_args[arg_idx].lower()\n",
    "                if pred not in filtered_events_preds:\n",
    "                    continue\n",
    "                arg = lemmatizer.lemmatize(arg, pos=wn.NOUN)\n",
    "                if arg.lower() in stopwords:\n",
    "                    continue\n",
    "\n",
    "                # Check if word is in the custom synset list\n",
    "                # Use WordNet lookup if not\n",
    "                if arg in synsets[schema_name]:\n",
    "                    syn_root = synsets[schema_name][arg]\n",
    "                else:\n",
    "                    if not wn.synsets(arg, pos=wn.NOUN):\n",
    "                        continue\n",
    "                    syn = wn.synsets(arg, pos=wn.NOUN)[0]\n",
    "                    if syn.hypernyms():\n",
    "                        syn_root = syn.hypernyms()[0].name()\n",
    "                    else:\n",
    "                        syn_root = syn.name()\n",
    "                if (pred, syn_root) in filtered_events:\n",
    "                    # doc_repr.append(f'{pred}_{syn_root}_{pred_idx}')\n",
    "                    doc_repr.append(f'{pred}__{syn_root}')\n",
    "                elif (pred,) in filtered_events:\n",
    "                    doc_repr.append(pred)\n",
    "            if len(doc_repr) > 1:\n",
    "                subset_raw_docs_ids.append(doc_id)\n",
    "                subset_raw_docs.append(doc_repr)\n",
    "                subset_event_cntr.update(doc_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8179"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('outnumber', 6166),\n",
       " ('concede', 4016),\n",
       " ('vote__civil_authority.n.01', 2760),\n",
       " ('elect__civil_authority.n.01', 2099),\n",
       " ('oust', 1752),\n",
       " ('congratulate', 614),\n",
       " ('endorse__campaigner.n.01', 257),\n",
       " ('defeat__campaigner.n.01', 96),\n",
       " ('nominate__campaigner.n.01', 72),\n",
       " ('campaign__campaigner.n.01', 30)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_event_cntr.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_raw_docs_ids = np.array(subset_raw_docs_ids)\n",
    "assert len(subset_raw_docs) == len(subset_raw_docs_ids)\n",
    "\n",
    "# Vectorize docs\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "subset_tfidf = vectorizer.fit_transform(subset_raw_docs)\n",
    "subset_tfidf = subset_tfidf.toarray()\n",
    "\n",
    "# Output to CSV\n",
    "header = [v for k, v in sorted([(v, k) for k, v in vectorizer.vocabulary_.items()])]\n",
    "vocab_size = len(vectorizer.vocabulary_)\n",
    "\n",
    "with open(f'{cgw_schema_rel_docs_path}/{schema_name}_binary_{vocab_size}_with_args.csv', 'w') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow(header)\n",
    "    for row in np.int32(subset_tfidf > 0):\n",
    "        writer.writerow(list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process narrative chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events = ['convict_0', 'face_1', 'sentence_0', 'arrest_0', 'accuse_1',\n",
    "                   'plead_1', 'acquit_0', 'indict_0', 'testify_1', 'charge_0']\n",
    "\n",
    "filtered_events_set = set(filtered_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_raw_docs_ids = []\n",
    "subset_raw_docs = []\n",
    "\n",
    "with open('../data/cgw/nytimes_chains.txt') as reader:\n",
    "    for ix, chain in tqdm(enumerate(reader)):\n",
    "        pred_only_chain = [x.replace('->nsubj', '_1').replace('->dobj', '_0') for x in chain.strip().split()]\n",
    "        subset_raw_docs_ids.append(ix)\n",
    "        subset_raw_docs.append(pred_only_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_raw_docs_ids = np.array(subset_raw_docs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False, vocabulary=filtered_events)\n",
    "subset_tfidf = vectorizer.fit_transform(subset_raw_docs)\n",
    "subset_tfidf = subset_tfidf.toarray()\n",
    "\n",
    "vocab_relevant_mask = (subset_tfidf.sum(axis=1) > 0)\n",
    "subset_tfidf = subset_tfidf[vocab_relevant_mask]\n",
    "subset_tfidf_ids = subset_raw_docs_ids[vocab_relevant_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to CSV\n",
    "\n",
    "header = [v for k, v in sorted([(v, k) for k, v in vectorizer.vocabulary_.items()])]\n",
    "vocab_size = len(vectorizer.vocabulary_)\n",
    "\n",
    "with open(f'../data/cgw/schema_related/pos/{schema_name}_tfidf_cj_{vocab_size}.csv', 'w') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow(header)\n",
    "    for doc_id, row in zip(subset_tfidf_ids, subset_tfidf):\n",
    "        writer.writerow(list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-project",
   "language": "python",
   "name": "causal-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
